{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6012, 64)\n",
      "(1508, 64)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from data.dataloader import ModelNet_aligned\n",
    "from model.DeepLatent_naive import *\n",
    "from model.networks import *\n",
    "from utils.utils import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "checkpoint_dir = 'results/'\n",
    "root = '/home/mmvc/mmvc-ny-nas/Yi_Shi/data/'\n",
    "save_name = os.path.join(checkpoint_dir,'model_best')\n",
    "\n",
    "\n",
    "# load latent_space\n",
    "z_space = torch.load(save_name+'_latents.pt',map_location='cpu')\n",
    "z_space_np = z_space.cpu().detach().numpy()\n",
    "print(z_space_np.shape)\n",
    "\n",
    "# load latent_objects (just test latent space)\n",
    "z_obj = torch.load(save_name+'_test_latents.pt',map_location='cpu')\n",
    "z_obj_np = z_obj.cpu().detach().numpy()\n",
    "print(z_obj_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mmvc/mmvc-ny-nas/Yi_Shi/data/gen/random_sample_gt_rate_2048/train\n",
      "6012 6012\n",
      "(6012, 40)\n"
     ]
    }
   ],
   "source": [
    "def read_cate_name(mode='train'):\n",
    "    dataset = ModelNet_aligned(root,None,mode=mode,downsample_num=2048)\n",
    "    indices = dataset.indices\n",
    "    categ = dataset.categ\n",
    "    names = dataset.npys_gen\n",
    "    names_instance = [os.path.split(i)[-1].split('.')[0] for i in names]\n",
    "    categs_instance = [categ.index('_'.join(i.split('_')[:-1])) for i in names_instance]\n",
    "    return names_instance,categs_instance\n",
    "\n",
    "def index2hot(indeces,rang=40):\n",
    "    num_ind = len(indeces)\n",
    "    b = np.zeros((num_ind,rang))\n",
    "    b[np.arange(num_ind), indeces] = 1\n",
    "    return b\n",
    "    \n",
    "names_instance,categs_instance = read_cate_name(mode='train')\n",
    "print(len(categs_instance),len(names_instance))\n",
    "y_test = index2hot(categs_instance)\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(ranked_relevant, num_relevant_retrievable):\n",
    "    \"\"\"Calculate average precision for a ranked set\n",
    "    ranked_relevant : np.array\n",
    "        ranked boolean array for whether the rank contained a relevant result\n",
    "    num_relevant_retrievable : int\n",
    "        number of possible relevant documents\n",
    "    Returns\n",
    "    -------\n",
    "    average_precision : np.float64\n",
    "    \"\"\"\n",
    "    # The rank will be used to divide to get precision for everything\n",
    "    # to that point\n",
    "    # based on: http://web.cecs.pdx.edu/~maier/cs510iri/IR_Lectures/CS_510iri_Lecture8RelevanceEvaluation-revised.pdf\n",
    "    # This is a tricky calculation to be honest\n",
    "    \n",
    "    rank = np.arange(ranked_relevant.shape[0]) + 1\n",
    "    indices = np.arange(ranked_relevant.shape[0])\n",
    "    relevant_indices = np.zeros(ranked_relevant.shape[0])\n",
    "    relevant_indices[indices[ranked_relevant]] = \\\n",
    "        np.cumsum(ranked_relevant[indices[ranked_relevant]])\n",
    "    return np.sum(relevant_indices/rank)/num_relevant_retrievable\n",
    "\n",
    "def query_latent_space(latent_object, latent_space, query_size=10):\n",
    "    \"\"\"Query a latent space (bottleneck features from NN)\n",
    "    latent_object : np.array\n",
    "        object as represented in an N-D space\n",
    "    latent_space : np.array\n",
    "        matrix of N-d latent vectors each representing a model\n",
    "        in your associated latent space\n",
    "    query_size : int\n",
    "        number of relevant items to retrieve\n",
    "    Returns\n",
    "    -------\n",
    "    top_n_sorted_sims : np.array\n",
    "        cosine similarities for the top n rows in latent_space\n",
    "        where n is specified by `query_size`\n",
    "    top_n_sorted_indices : np.array\n",
    "        indices of top n rows from the latent_space\n",
    "    \"\"\"\n",
    "    sims = latent_space.dot(latent_object.T)\n",
    "    sorted_sims_indices = np.argpartition(sims,\n",
    "                                          range(-query_size, 0),\n",
    "                                          axis=0)\n",
    "    top_n_sorted_indices = sorted_sims_indices[:-query_size-1:-1].ravel()\n",
    "    top_n_sorted_sims = sims[top_n_sorted_indices].ravel()\n",
    "    return top_n_sorted_sims, top_n_sorted_indices\n",
    "\n",
    "\n",
    "\n",
    "def _get_average_precisions(latent_space, x_latent_test, y_test):\n",
    "    test_size = x_latent_test.shape[0]\n",
    "    average_precisions = np.zeros(test_size)\n",
    "    for i in range(test_size):\n",
    "        if i % 100 == 0:\n",
    "            print('precisions_done_calculating_{}'.format(i))\n",
    "        num = i\n",
    "        num_retrievable = (np.argmax(y_test[num]) == \\\n",
    "                               np.argmax(y_test, axis=1)).sum()\n",
    "        # latent_object = latent_model.predict(x_test[num:num+1])\n",
    "        latent_object = latent_space[num: num+1]\n",
    "        sims, latent_indices = query_latent_space(latent_object,\n",
    "                                                  latent_space,\n",
    "                                                  test_size)\n",
    "        ranked_relevant = np.argmax(y_test[num]) ==\\\n",
    "                            np.argmax(y_test[latent_indices], axis=1)\n",
    "\n",
    "        average_precisions[i] = average_precision(ranked_relevant, num_retrievable)\n",
    "    return average_precisions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisions_done_calculating_0\n",
      "precisions_done_calculating_100\n",
      "precisions_done_calculating_200\n",
      "precisions_done_calculating_300\n",
      "precisions_done_calculating_400\n",
      "precisions_done_calculating_500\n",
      "precisions_done_calculating_600\n",
      "precisions_done_calculating_700\n",
      "precisions_done_calculating_800\n",
      "precisions_done_calculating_900\n",
      "precisions_done_calculating_1000\n",
      "precisions_done_calculating_1100\n",
      "precisions_done_calculating_1200\n",
      "precisions_done_calculating_1300\n",
      "precisions_done_calculating_1400\n",
      "precisions_done_calculating_1500\n",
      "precisions_done_calculating_1600\n",
      "precisions_done_calculating_1700\n",
      "precisions_done_calculating_1800\n",
      "precisions_done_calculating_1900\n",
      "precisions_done_calculating_2000\n",
      "precisions_done_calculating_2100\n",
      "precisions_done_calculating_2200\n",
      "precisions_done_calculating_2300\n",
      "precisions_done_calculating_2400\n",
      "precisions_done_calculating_2500\n",
      "precisions_done_calculating_2600\n",
      "precisions_done_calculating_2700\n",
      "precisions_done_calculating_2800\n",
      "precisions_done_calculating_2900\n",
      "precisions_done_calculating_3000\n",
      "precisions_done_calculating_3100\n",
      "precisions_done_calculating_3200\n",
      "precisions_done_calculating_3300\n",
      "precisions_done_calculating_3400\n",
      "precisions_done_calculating_3500\n",
      "precisions_done_calculating_3600\n",
      "precisions_done_calculating_3700\n",
      "precisions_done_calculating_3800\n",
      "precisions_done_calculating_3900\n",
      "precisions_done_calculating_4000\n",
      "precisions_done_calculating_4100\n",
      "precisions_done_calculating_4200\n",
      "precisions_done_calculating_4300\n",
      "precisions_done_calculating_4400\n",
      "precisions_done_calculating_4500\n",
      "precisions_done_calculating_4600\n",
      "precisions_done_calculating_4700\n",
      "precisions_done_calculating_4800\n",
      "precisions_done_calculating_4900\n",
      "precisions_done_calculating_5000\n",
      "precisions_done_calculating_5100\n",
      "precisions_done_calculating_5200\n",
      "precisions_done_calculating_5300\n",
      "precisions_done_calculating_5400\n",
      "precisions_done_calculating_5500\n",
      "precisions_done_calculating_5600\n",
      "precisions_done_calculating_5700\n",
      "precisions_done_calculating_5800\n",
      "precisions_done_calculating_5900\n",
      "precisions_done_calculating_6000\n",
      "[0.01990092 0.02778961 0.01923565 ... 0.01577839 0.01951994 0.01588999]\n"
     ]
    }
   ],
   "source": [
    "average_precisions = _get_average_precisions(z_space_np, z_space_np, y_test)\n",
    "print(average_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
